<여러형태의 딥러닝 모델 살펴보기>

1) 학습방식 기반
: 지도(분류) / 비지도(군집)(노이즈 줄이는 영상) / 강화(알파고)(잘못되면 패널티 줌)

인공지능과 학습 - 지도학습, 비지도학습, 강화학습(유튜브)(소프트웨어야 놀자)

비지도 학습 
→ 군집화(clustering)
→ 없는 것을 만들어냄(GAN)
+ """
no-reference
full-reference → 평가하기 쉬움(값이 절대적이므로)
reduced-reference
 + PSNR(peak to signal noise ratio) / SSIM, GMSD, LPIPS """

강화학습의 어려운 점?
 - 초기에 어떤 보상을 주어야 학습이 잘 될지 고민을 해야함

ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ

2) 아키텍처 기반
1. Perceptron
1) Single-layer Perceptron
뉴런 → 축삭돌기 → 뉴런
노드 →  가중치  → 노드
2) Multi-layer Perceptron

2. CNN(합성곱 신경망)
1) 인간의 시신경 구조 모방(디자인 분야)
 / 다수의 Convolutional Layer으로부터 특징맵을 추출하고 서브샘플링(특징들의 패턴파악) →차원축소
convolution과정 + pooling과정
 / 이미지 분류, semantic segmentation 등
+ ResNet : 구글에 쳐보기(잔차를 합산)
+ 알파고 : 13개의 은닉층을 가진 CNN
+ https://www.colorized.com/

이미지에서 나온 패치(patch)들을 필터(kernel)를 거쳐서 학습을 하는 과정
→ CNN이 학습되는 과정

차원을 축소하는 레이어 : Pooling layer → Max pooling(흔히 사용) / average pooling


3. RNN(순환신경망) : 뉴런의 출력이 다시 입력으로 feedback되는 재귀적인 연결 구조를 갖는 신경망
과거데이터를 통해 미래어떤 데이터를 가질 것이다라는 쪽으로 사용(한계 : 과거 데이터 기반이므로 미래 데이터에
확신을 하진 못한다) / hidden layer에 과거의 정보가 들어있다 / ex) 파파고, 구글 번역기

4. GAN(Generative adversarial networks)(생산석 적대 신경망)
G : "생산하는" 이라는 뜻(이미지 생산) / A : ''적대적인''이란 뜻 / 서로 경쟁하면서 좋게 만든다
+ https://generated.photos/

classification 문제는 접근법은 
discriminative model(판별 모델)(원본과 얼마나 비슷할지 비교 판단)
vs generator model(생성모델)(높은 해상도 만드는 역할) 두 개가 합침(서로 경쟁하면서 더 좋은 이미지를 만들어 내는 과정)
augmenting a dataset : 가장 그럴듯한 데이터셋을 만들어서 이미지 만듦

+ GAN과 비슷한 application: 오토인코더(의학분야의 x레이나 mri사진을 가지고 이미지를 만드는거...)
(낮은 이미지를 점차 큰 이미지로 만드는거)
+ stylegan

유튜브 영상 : 

한번에 끝내는 인공지능


5. Transformers(요새 젤 핫함)(RNN사용X, 인코더-디코더 구조 설계임에도 불구하고 RNN보다 우수)
대표적 모델 : GPT-3  / BERT

ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ


conda activate pytorch
cd C:\Users\11\Desktop\pytorch
jupyter notebook

ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ
<실습>
추가해야할 것
convolution 레이어 3개 추가하기
에폭은 300

ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ
Classifier training

cifar10 : 여러 이미지가 들어 있는 데이터 셋
+ kaggle: 사용자 데이터셋을 다운로드 받을 수 있는 곳
+ torchvision : 주로많이 사용되는 데이터셋만 지원
(ex) Cifar 10, MNIST, MNIST-fashion, IMAGENET, Celeb_A, DIV2K) : 이미지 트레이닝에 유용한 데이터 셋
Cifar10 , Cifar 100도 써도 됨(좀더 많은 라벨링이 있음)
ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ

+ ILSVRC 대회 / + googlenet v4

ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ

conda install pandas
conda install scikit-learn

Fashion MNIST : 총 60,000개 훈련 데이터, 28*28 1차원 이미지(흑백) / 총 10,000개의 테스트셋

ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ

.pth로 저장된 모델을 시각화 하고 싶을 경우 → netron(모델을 그림으로 확인할 수 있음)
torchsummary

++그냥 내가
https://honeyjamtech.tistory.com/40 참고


nvidia-smi를 promt에 입력하면 GPU가 사용되고 있는지 확인할 수 있음

현재 GPU를 이요해서 훈련이 진행되는지 확인하는 방법
1) 터미널(PowerShell)에서 확인하기
powershell를 실행후
→ while(1) {nvidia-smi; start-sleep -seconds 5;clear) 입력

2) 작업관리자 → 성능 → GPU → cuda 퍼센테이지가 올라가는지 확인




